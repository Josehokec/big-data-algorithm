# big-data-algorithm

参考网址：https://soulmachine.gitbooks.io/system-design/content/cn/bigdata/range-query.html

## 1.Reservoir Sampling

### Question Description: 有一个无限的整数数据流，如何从中随机地抽取k个整数出来？

---
我们先考虑最简单的情况，k=1，即只需要随机抽取一个样本出来。抽样方法如下：

1.当第一个整数到达时，保存该整数

2.当第2个整数到达时，以1/2的概率使用该整数替换第1个整数，以1/2的概率丢弃改整数

3.当第i个整数到达时，以1/i的概率使用第i个整数替换被选中的整数，以1-1/i的概率丢弃第i个整数

假设数据流目前已经流出共n个整数，下面证明上述方法能保证每个元素被选中的概率是1/n

采用数学归纳法证明：

1.当n=1时，由于是第1个数，被选中的概率是100%，命题成立

2.假设当n=m(m>=1)时，命题成立，即前m个数，每一个被选中的概率是 $$?\frac{1}{m}?

3.当n=m+1时，第m+1个数被选中的概率是1/(1+m) , 前m个数被选中的概率是(即前m个元素某一个被选中的概率* 没有被第m+1元素踢掉的概率):
1/m(1-1/(m+1))=1/(m+1) ，命题依然成立

于是对于所有的n={1,2,3,4...},结论都成立。

---
当 k > 1，需要随机采样多个样本时，方法跟上面很类似，

1.前k个整数到达时，全部保留，即被选中的概率是 100%，

2.第i个整数到达时，以k/i的概率替换k个数中的某一个，以1-k/i的概率丢弃，保留k个数不变


假设数据流目前已经流出共N个整数，下面证明这个方法能保证每个元素被选中的概率都是k/N，证明如下：

1.当n=m(m<=k)时，被选中的概率是100%，命题成立

2.假设当n=m(m>k)时，命题成立，即前m个数，每一个被选中的概率是1/m

3.当n=m+1时，第m+1个数被选中的概率是k/(m+1), 前m个数被选中的概率是(选中的概率 * 不被踢出去，两种情况不会被踢出去):
1/m*(k/(m+1) * (1-1/k) + 1 - k/(m+1))=1/(m+1)，命题依然成立
于是对于所有的n={1,2,3,4...},结论都成立。

## Cardinality Estimation
### Question Description: 如何计算数据流中不同元素的个数？

首先最容易想到的办法是用HashSet，每来一个元素，就往里面塞，HashSet的大小就所求答案。但是在大数据的场景下，HashSet在单机内存中存不下。

HashSet耗内存主要是由于存储了元素的真实值，可不可以不存储元素本身呢？bitmap就是这样一个方案，假设已经知道不同元素的个数的上限，即基数的最大值，设为N，则开一个长度为N的bit数组，地位跟HashSet一样。每个元素与bit数组的某一位一一对应，该位为1，表示此元素在集合中，为0表示不在集合中。那么bitmap中1的个数就是所求答案。

这个方案的缺点是，bitmap的长度与实际的基数无关，而是与基数的上限有关。假如要计算上限为1亿的基数，则需要12.5MB的bitmap。关键在于，这个内存使用与集合元素数量无关，即使一个网站仅仅有一个1个访客，也要为其分配12.5MB内存。

实际上目前还没有发现在大数据场景中准确计算基数的高效算法，因此在不追求绝对准确的情况下，使用近似算法算是一个不错的解决方案。

---
Linear Counting Algorithm：

1.选择一个哈希函数h，其结果服从均匀分布
2.开一个长度为m的bitmap，均初始化为0(m设为多大后面有讨论)
3.数据流每来一个元素，计算其哈希值并对m取模，然后将该位置为1

在使用Linear Counting算法时，主要需要考虑的是bitmap长度m。m主要由两个因素决定，基数大小以及容许的误差。假设基数大约为n，允许的误差为ϵ，则m需要满足如下约束：

m > (ϵ^t-t-1)/((ϵt)^2), where t=n/m

精度越高，需要的m越大。Linear Counting 与bitmap很类似，只是改善了bitmap的内存占用，但并没有完全解决，例如一个网站只有一个访客，依然要为其分配m位的bitmap。


